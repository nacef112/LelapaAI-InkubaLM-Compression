# ğŸ§  InkubaLM Compression for Swahili & Hausa  
### ğŸ¥‰ Bronze Medal Solution â€“ Zindi Lelapa AI Buzuzu-Mavi Challenge

---

## ğŸš€ Overview

Open-source language models often underperform on African languages and demand high computational resourcesâ€”barriers to real-world use in the African context. To make language AI truly inclusive, we need models that are **smaller**, **smarter**, and optimized for **resource-constrained environments**.

The **Lelapa AI Buzuzu-Mavi Challenge** tasked participants with compressing Lelapa AIâ€™s *InkubaLM*â€”an open-source small language model (SLM)â€”while **maintaining or improving performance** for two key African languages: **Swahili** and **Hausa**.

This repository presents our **Bronze Medal-winning solution**. ğŸ¥‰

---

## ğŸ¯ Objectives

âœ… Compress InkubaLM to reduce size and inference cost  
âœ… Retain or improve model accuracy on core NLP tasks  
âœ… Ensure usability on low-resource devices and CPUs  
âœ… Focus on **Swahili** and **Hausa** performance

---

## ğŸ§ª Tasks & Evaluation

The model was evaluated across three NLP tasks:

- ğŸ—£ï¸ **Sentiment Analysis**  
- ğŸ§  **Natural Language Inference** (AfriXNLI â€“ true/false reasoning)  
- ğŸŒ **Machine Translation** (English â†’ Swahili & Hausa)

Performance could be improved by either:
- Increasing task accuracy,
- Reducing model size,  
- Or both.

---

## ğŸ› ï¸ Techniques Applied

ğŸ”§ **Quantization** â€“ Reduced precision (8-bit & 4-bit) for faster, leaner models  
âœ‚ï¸ **Pruning** â€“ Removed redundant parameters  
ğŸŒ **Language-Specific Fine-tuning** â€“ Custom fine-tuning on Swahili and Hausa datasets

---

## ğŸŒ Why It Matters

This work moves us closer to a future where African languages have **equal representation** in the AI ecosystem. Smaller, smarter models enable:

- âœ… Faster NLP on standard CPUs  
- âœ… Offline language tools  
- âœ… Scalable deployment in education, agriculture, health, and customer service  

---

## ğŸ—ï¸ Repository Structure

